{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-18 22:03:34.516971: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import tensorflow as tf\n",
    "from transformers import GPT2Tokenizer, TFAutoModel\n",
    "from scipy.stats.stats import pearsonr\n",
    "from scipy.stats import spearmanr"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Read dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def create_dataset(path_file: str, name_model: str, block_size: int, batch_size: int) -> tf.data.Dataset:\n",
    "    sentences_1 = []\n",
    "    sentences_2 = []\n",
    "    similarities = []\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained(name_model)\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "    with open(path_file, 'r') as input_file:\n",
    "\n",
    "        for line in input_file.readlines():\n",
    "            if line.strip() == '':\n",
    "                continue\n",
    "\n",
    "            similarity, sentence1, sentence2 = line.strip().split('\\t')\n",
    "            sentences_1.append(sentence1)\n",
    "            sentences_2.append(sentence2)\n",
    "            similarities.append(float(similarity) / 5)\n",
    "\n",
    "    sentences_1 = tokenizer(sentences_1, padding='max_length', max_length=block_size, truncation=True,\n",
    "                            return_tensors='tf')\n",
    "    sentences_2 = tokenizer(sentences_2, padding='max_length', max_length=block_size, truncation=True,\n",
    "                            return_tensors='tf')\n",
    "    similarities = tf.convert_to_tensor(similarities, dtype=tf.float32)\n",
    "\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((\n",
    "        {'sentence1_ids': sentences_1['input_ids'], 'sentence2_ids': sentences_2['input_ids'], }, similarities))\n",
    "    dataset = dataset.shuffle(10_000).batch(batch_size=batch_size, drop_remainder=True)\n",
    "\n",
    "    return dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load trained model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "class CosineSimilarity(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, name=None, **kwarg):\n",
    "        super(CosineSimilarity, self).__init__(name=name, **kwarg)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        pass\n",
    "\n",
    "    def call(self, a: tf.Tensor, b: tf.Tensor):\n",
    "        a_norm = tf.math.l2_normalize(a, axis=-1)\n",
    "        b_norm = tf.math.l2_normalize(b, axis=-1)\n",
    "\n",
    "        return tf.reduce_sum(tf.multiply(a_norm, b_norm), axis=-1)\n",
    "\n",
    "\n",
    "def create_model(path_pre_trained: str, block_size: int, batch_size: int) -> tf.keras.models.Model:\n",
    "    gpt2 = TFAutoModel.from_pretrained(path_pre_trained)\n",
    "\n",
    "    sentence1_layer = tf.keras.layers.Input(shape=block_size, batch_size=batch_size, name='sentence1_ids',\n",
    "                                            dtype=tf.int32)\n",
    "    sentence2_layer = tf.keras.layers.Input(shape=block_size, batch_size=batch_size, name='sentence2_ids',\n",
    "                                            dtype=tf.int32)\n",
    "\n",
    "    sentence1_embedding = gpt2(sentence1_layer, return_dict=True).last_hidden_state\n",
    "    sentence2_embedding = gpt2(sentence2_layer, return_dict=True).last_hidden_state\n",
    "\n",
    "    vec_sentence1 = tf.keras.layers.Lambda(lambda x: tf.math.reduce_mean(x, axis=1))(sentence1_embedding)\n",
    "    vec_sentence2 = tf.keras.layers.Lambda(lambda x: tf.math.reduce_mean(x, axis=1))(sentence2_embedding)\n",
    "\n",
    "    output_layer = CosineSimilarity(name='similarity')(vec_sentence1, vec_sentence2)\n",
    "\n",
    "    return tf.keras.models.Model(inputs=[sentence1_layer, sentence2_layer], outputs=[output_layer])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Eval Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def _eval_model(model: tf.keras.models.Model, ds: tf.data.Dataset) -> float:\n",
    "    predicts = []\n",
    "    values = []\n",
    "\n",
    "    for x, y in ds:\n",
    "        predict = model(x)\n",
    "        values += [float(i) for i in list(y.numpy())]\n",
    "        predicts += list(predict.numpy())\n",
    "\n",
    "    return spearmanr(predicts, values)[0], pearsonr(predicts, values)[0]\n",
    "\n",
    "\n",
    "def eval_rosts(model: tf.keras.Model, ds_dev: tf.data.Dataset, ds_test: tf.data.Dataset, path_log: str):\n",
    "    name_model = path_log.split('/')[-1].replace('txt', '')\n",
    "\n",
    "    spearman_dev, pearson_dev = _eval_model(model, ds_dev)\n",
    "    spearman_test, pearson_test = _eval_model(model, ds_test)\n",
    "\n",
    "    Path(os.path.dirname(path_log)).mkdir(parents=True, exist_ok=True)\n",
    "    with open(f'{path_log}', 'w+') as output_file:\n",
    "        output_file.write(f'For dev: spearman: {spearman_dev}, pearson: {pearson_dev}\\n')\n",
    "        output_file.write(f'For test: spearman: {spearman_test}, pearson: {pearson_test}\\n')\n",
    "\n",
    "    print(f'\\nFor model: {name_model}\\n')\n",
    "    print(f'For dev: spearman: {spearman_dev}, pearson: {pearson_dev}')\n",
    "    print(f'For test: spearman: {spearman_test}, pearson: {pearson_test}\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Run evaluation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-18 22:04:09.465208: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-07-18 22:04:09.469314: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2021-07-18 22:04:09.566340: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: GeForce RTX 2060 computeCapability: 7.5\n",
      "coreClock: 1.2GHz coreCount: 30 deviceMemorySize: 5.79GiB deviceMemoryBandwidth: 312.97GiB/s\n",
      "2021-07-18 22:04:09.566423: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-07-18 22:04:09.570164: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2021-07-18 22:04:09.570265: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-07-18 22:04:09.571596: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2021-07-18 22:04:09.571878: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2021-07-18 22:04:09.573049: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-07-18 22:04:09.573617: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2021-07-18 22:04:09.573788: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-07-18 22:04:09.575199: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2021-07-18 22:04:09.575576: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-07-18 22:04:09.575954: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-07-18 22:04:09.576514: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: GeForce RTX 2060 computeCapability: 7.5\n",
      "coreClock: 1.2GHz coreCount: 30 deviceMemorySize: 5.79GiB deviceMemoryBandwidth: 312.97GiB/s\n",
      "2021-07-18 22:04:09.576547: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-07-18 22:04:09.576582: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2021-07-18 22:04:09.576600: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-07-18 22:04:09.576616: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2021-07-18 22:04:09.576632: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2021-07-18 22:04:09.576649: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-07-18 22:04:09.576665: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2021-07-18 22:04:09.576681: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-07-18 22:04:09.577585: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2021-07-18 22:04:09.577617: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-07-18 22:04:10.035228: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-07-18 22:04:10.035250: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2021-07-18 22:04:10.035256: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2021-07-18 22:04:10.036349: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 4954 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5)\n"
     ]
    }
   ],
   "source": [
    "block_size = 64\n",
    "batch_size_dev = 15  # total size: 1500\n",
    "batch_size_test = 7  # total size: 1379\n",
    "path_tokenizer = '../../../model/tokenizer'\n",
    "path_ds_dev = '../../../dataset/ro-sts/raw/RO-STS.dev.tsv'\n",
    "path_ds_test = '../../../dataset/ro-sts/raw/RO-STS.test.tsv'\n",
    "\n",
    "ds_dev = create_dataset(path_ds_dev, path_tokenizer, block_size, batch_size_dev)\n",
    "ds_test = create_dataset(path_ds_test, path_tokenizer, block_size, batch_size_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Base"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFGPT2Model.\n",
      "\n",
      "All the layers of TFGPT2Model were initialized from the model checkpoint at ../../../model/evaluation/ro-sts/base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2Model for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "\n",
      "For model: base.\n",
      "\n",
      "For dev: spearman: 0.8351764008907624, pearson: 0.8374689010467199\n",
      "For test: spearman: 0.7977757024235947, pearson: 0.8056467384626317\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path_model = '../../../model/evaluation/ro-sts/base'\n",
    "name_model = path_model.split('/')[-1]\n",
    "model = create_model(path_model, block_size, max(batch_size_test, batch_size_dev))\n",
    "eval_rosts(model, ds_dev, ds_test, f'../../../log/ro-sts/{name_model}.txt')\n",
    "del model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Medium"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFGPT2Model.\n",
      "\n",
      "All the layers of TFGPT2Model were initialized from the model checkpoint at ../../../model/evaluation/ro-sts/medium.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2Model for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "\n",
      "For model: medium.\n",
      "\n",
      "For dev: spearman: 0.8575904794681395, pearson: 0.8604237133158215\n",
      "For test: spearman: 0.8225375656733844, pearson: 0.8316273781489802\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path_model = '../../../model/evaluation/ro-sts/medium'\n",
    "name_model = path_model.split('/')[-1]\n",
    "model = create_model(path_model, block_size, max(batch_size_test, batch_size_dev))\n",
    "eval_rosts(model, ds_dev, ds_test, f'../../../log/ro-sts/{name_model}.txt')\n",
    "del model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Large"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFGPT2Model.\n",
      "\n",
      "All the layers of TFGPT2Model were initialized from the model checkpoint at ../../../model/evaluation/ro-sts/large.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2Model for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "\n",
      "For model: large.\n",
      "\n",
      "For dev: spearman: 0.8570196916889122, pearson: 0.8614030174418702\n",
      "For test: spearman: 0.8264904791801911, pearson: 0.8346437952105512\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path_model = '../../../model/evaluation/ro-sts/large'\n",
    "name_model = path_model.split('/')[-1]\n",
    "model = create_model(path_model, block_size, max(batch_size_test, batch_size_dev))\n",
    "eval_rosts(model, ds_dev, ds_test, f'../../../log/ro-sts/{name_model}.txt')\n",
    "del model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}