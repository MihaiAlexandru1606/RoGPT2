{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from pathlib import Path\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Preprocessing Function"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def fix_quotation_marks(line: str) -> str:\n",
    "    line = re.sub(chr(8222), chr(34), line)\n",
    "    line = re.sub(chr(8221), chr(34), line)\n",
    "    line = line.replace(\"\\n\", \"\")\n",
    "    line = re.sub(\"\\s+\", ' ', line)\n",
    "\n",
    "    return line\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Evaluation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def evaluation():\n",
    "    path_generate = '../../../generate/rogec'\n",
    "    path_log = '../../../log/rogec'\n",
    "\n",
    "    for path_dirs in [str(x) for x in Path(path_generate).glob(\"*\") if x.is_dir()]:\n",
    "        name_ds = path_dirs.split('/')[-1]\n",
    "\n",
    "        for path_version_dirs in [str(x) for x in Path(path_dirs).glob('*') if x.is_dir()]:\n",
    "            name_version = path_version_dirs.split('/')[-1]\n",
    "\n",
    "            Path(f'{path_log}/{name_ds}/{name_version}').mkdir(exist_ok=True, parents=True)\n",
    "            for file in [str(x) for x in Path(path_version_dirs).glob(\"*.json\") if x.is_file()]:\n",
    "                print(f\"Evaluate : {file}\\n\")\n",
    "                generate_method = file.split('/')[-1].replace('.json', '')\n",
    "\n",
    "                originals = []\n",
    "                predicts = []\n",
    "                inputs = []\n",
    "\n",
    "                # extract from generate\n",
    "                with open(file, 'r') as input_file:\n",
    "                    data = json.load(input_file)\n",
    "\n",
    "                for i in data:\n",
    "                    originals.append(fix_quotation_marks(i['original']))\n",
    "                    predicts.append(fix_quotation_marks(i['predict']))\n",
    "                    inputs.append(fix_quotation_marks(i['input']))\n",
    "\n",
    "                with open('correct.txt', 'w+') as output_file:\n",
    "                    for line in originals:\n",
    "                        output_file.write(f'{line}\\n')\n",
    "\n",
    "                with open('predict.txt', 'w+') as output_file:\n",
    "                    for line in predicts:\n",
    "                        output_file.write(f'{line}\\n')\n",
    "\n",
    "                with open('input.txt', 'w+') as output_file:\n",
    "                    for line in inputs:\n",
    "                        output_file.write(f'{line}\\n')\n",
    "\n",
    "                # eval input\n",
    "                os.system(\n",
    "                    f'python3.8 ERRANT/parallel_to_m2.py -orig input.txt -cor correct.txt -out out_ref.txt -lang ro > /dev/null 2>&1')\n",
    "\n",
    "                # eval predict\n",
    "                os.system(\n",
    "                    f'python3.8 ERRANT/parallel_to_m2.py -orig predict.txt -cor correct.txt -out out_hyp.txt -lang ro > /dev/null 2>&1')\n",
    "\n",
    "                if os.path.exists(f'{path_log}/{name_ds}/{name_version}/{generate_method}.txt'):\n",
    "                    os.remove(f'{path_log}/{name_ds}/{name_version}/{generate_method}.txt')\n",
    "\n",
    "                # logging results\n",
    "                os.system(\n",
    "                    f'python3 ERRANT/compare_m2.py -hyp out_hyp.txt -ref out_ref.txt >> {path_log}/{name_ds}/{name_version}/{generate_method}.txt'\n",
    "                )\n",
    "                print(f'\\Results for model: {name_version}, decoder method: {generate_method} trained on the ds: {name_ds}')\n",
    "                os.system(f'cat {path_log}/{name_ds}/{name_version}/{generate_method}.txt')\n",
    "                print()\n",
    "\n",
    "                os.system(\n",
    "                    f'python3 ERRANT/compare_m2.py -hyp out_hyp.txt -ref out_ref.txt -cse >> {path_log}/{name_ds}/{name_version}/{generate_method}.txt'\n",
    "                )\n",
    "\n",
    "                os.system(\n",
    "                    f'python3 ERRANT/compare_m2.py -hyp out_hyp.txt -ref out_ref.txt -ds >> {path_log}/{name_ds}/{name_version}/{generate_method}.txt'\n",
    "                )\n",
    "\n",
    "                os.system(\n",
    "                    f'python3 ERRANT/compare_m2.py -hyp out_hyp.txt -ref out_ref.txt -dt >> {path_log}/{name_ds}/{name_version}/{generate_method}.txt'\n",
    "                )\n",
    "\n",
    "    # clean-up\n",
    "    os.remove('correct.txt')\n",
    "    os.remove('predict.txt')\n",
    "    os.remove('input.txt')\n",
    "    os.remove('out_ref.txt')\n",
    "    os.remove('out_hyp.txt')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Run evaluation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate : ../../../generate/rogec/smaller-dataset/base/base-beam-search-4.json\n",
      "\n",
      "\\Results for model: base, decoder method: base-beam-search-4 trained on the ds: smaller-dataset\n",
      "\n",
      "=========== Span-Based Correction ============\n",
      "TP\tFP\tFN\tPrec\tRec\tF0.5\n",
      "1169\t623\t1204\t0.6523\t0.4926\t0.6126\n",
      "==============================================\n",
      "\n",
      "\n",
      "Evaluate : ../../../generate/rogec/smaller-dataset/base/base-greedy.json\n",
      "\n",
      "\\Results for model: base, decoder method: base-greedy trained on the ds: smaller-dataset\n",
      "\n",
      "=========== Span-Based Correction ============\n",
      "TP\tFP\tFN\tPrec\tRec\tF0.5\n",
      "1171\t813\t1202\t0.5902\t0.4935\t0.568\n",
      "==============================================\n",
      "\n",
      "\n",
      "Evaluate : ../../../generate/rogec/smaller-dataset/base/base-beam-search-8.json\n",
      "\n",
      "\\Results for model: base, decoder method: base-beam-search-8 trained on the ds: smaller-dataset\n",
      "\n",
      "=========== Span-Based Correction ============\n",
      "TP\tFP\tFN\tPrec\tRec\tF0.5\n",
      "1178\t610\t1195\t0.6588\t0.4964\t0.6184\n",
      "==============================================\n",
      "\n",
      "\n",
      "Evaluate : ../../../generate/rogec/smaller-dataset/medium/medium-beam-search-4.json\n",
      "\n",
      "\\Results for model: medium, decoder method: medium-beam-search-4 trained on the ds: smaller-dataset\n",
      "\n",
      "=========== Span-Based Correction ============\n",
      "TP\tFP\tFN\tPrec\tRec\tF0.5\n",
      "1376\t523\t997\t0.7246\t0.5799\t0.6901\n",
      "==============================================\n",
      "\n",
      "\n",
      "Evaluate : ../../../generate/rogec/smaller-dataset/medium/medium-beam-search-8.json\n",
      "\n",
      "\\Results for model: medium, decoder method: medium-beam-search-8 trained on the ds: smaller-dataset\n",
      "\n",
      "=========== Span-Based Correction ============\n",
      "TP\tFP\tFN\tPrec\tRec\tF0.5\n",
      "1369\t526\t1004\t0.7224\t0.5769\t0.6877\n",
      "==============================================\n",
      "\n",
      "\n",
      "Evaluate : ../../../generate/rogec/smaller-dataset/medium/medium-greedy.json\n",
      "\n",
      "\\Results for model: medium, decoder method: medium-greedy trained on the ds: smaller-dataset\n",
      "\n",
      "=========== Span-Based Correction ============\n",
      "TP\tFP\tFN\tPrec\tRec\tF0.5\n",
      "1375\t590\t998\t0.6997\t0.5794\t0.6718\n",
      "==============================================\n",
      "\n",
      "\n",
      "Evaluate : ../../../generate/rogec/smaller-dataset/large/large-beam-search-4.json\n",
      "\n",
      "\\Results for model: large, decoder method: large-beam-search-4 trained on the ds: smaller-dataset\n",
      "\n",
      "=========== Span-Based Correction ============\n",
      "TP\tFP\tFN\tPrec\tRec\tF0.5\n",
      "1173\t625\t1200\t0.6524\t0.4943\t0.6132\n",
      "==============================================\n",
      "\n",
      "\n",
      "Evaluate : ../../../generate/rogec/smaller-dataset/large/large-beam-search-8.json\n",
      "\n",
      "\\Results for model: large, decoder method: large-beam-search-8 trained on the ds: smaller-dataset\n",
      "\n",
      "=========== Span-Based Correction ============\n",
      "TP\tFP\tFN\tPrec\tRec\tF0.5\n",
      "1168\t630\t1205\t0.6496\t0.4922\t0.6106\n",
      "==============================================\n",
      "\n",
      "\n",
      "Evaluate : ../../../generate/rogec/smaller-dataset/large/large-greedy.json\n",
      "\n",
      "\\Results for model: large, decoder method: large-greedy trained on the ds: smaller-dataset\n",
      "\n",
      "=========== Span-Based Correction ============\n",
      "TP\tFP\tFN\tPrec\tRec\tF0.5\n",
      "1165\t717\t1208\t0.619\t0.4909\t0.5883\n",
      "==============================================\n",
      "\n",
      "\n",
      "Evaluate : ../../../generate/rogec/1gb-dataset/base/base-beam-search-4.json\n",
      "\n",
      "\\Results for model: base, decoder method: base-beam-search-4 trained on the ds: 1gb-dataset\n",
      "\n",
      "=========== Span-Based Correction ============\n",
      "TP\tFP\tFN\tPrec\tRec\tF0.5\n",
      "1199\t486\t1174\t0.7116\t0.5053\t0.6579\n",
      "==============================================\n",
      "\n",
      "\n",
      "Evaluate : ../../../generate/rogec/1gb-dataset/base/base-greedy.json\n",
      "\n",
      "\\Results for model: base, decoder method: base-greedy trained on the ds: 1gb-dataset\n",
      "\n",
      "=========== Span-Based Correction ============\n",
      "TP\tFP\tFN\tPrec\tRec\tF0.5\n",
      "1177\t537\t1196\t0.6867\t0.496\t0.6377\n",
      "==============================================\n",
      "\n",
      "\n",
      "Evaluate : ../../../generate/rogec/1gb-dataset/base/base-beam-search-8.json\n",
      "\n",
      "\\Results for model: base, decoder method: base-beam-search-8 trained on the ds: 1gb-dataset\n",
      "\n",
      "=========== Span-Based Correction ============\n",
      "TP\tFP\tFN\tPrec\tRec\tF0.5\n",
      "1202\t475\t1171\t0.7168\t0.5065\t0.6618\n",
      "==============================================\n",
      "\n",
      "\n",
      "Evaluate : ../../../generate/rogec/1gb-dataset/medium/medium-beam-search-4.json\n",
      "\n",
      "\\Results for model: medium, decoder method: medium-beam-search-4 trained on the ds: 1gb-dataset\n",
      "\n",
      "=========== Span-Based Correction ============\n",
      "TP\tFP\tFN\tPrec\tRec\tF0.5\n",
      "1039\t482\t1334\t0.6831\t0.4378\t0.6143\n",
      "==============================================\n",
      "\n",
      "\n",
      "Evaluate : ../../../generate/rogec/1gb-dataset/medium/medium-beam-search-8.json\n",
      "\n",
      "\\Results for model: medium, decoder method: medium-beam-search-8 trained on the ds: 1gb-dataset\n",
      "\n",
      "=========== Span-Based Correction ============\n",
      "TP\tFP\tFN\tPrec\tRec\tF0.5\n",
      "1044\t476\t1329\t0.6868\t0.4399\t0.6175\n",
      "==============================================\n",
      "\n",
      "\n",
      "Evaluate : ../../../generate/rogec/1gb-dataset/medium/medium-greedy.json\n",
      "\n",
      "\\Results for model: medium, decoder method: medium-greedy trained on the ds: 1gb-dataset\n",
      "\n",
      "=========== Span-Based Correction ============\n",
      "TP\tFP\tFN\tPrec\tRec\tF0.5\n",
      "1028\t738\t1345\t0.5821\t0.4332\t0.5447\n",
      "==============================================\n",
      "\n",
      "\n",
      "Evaluate : ../../../generate/rogec/1gb-dataset/large/large-beam-search-4.json\n",
      "\n",
      "\\Results for model: large, decoder method: large-beam-search-4 trained on the ds: 1gb-dataset\n",
      "\n",
      "=========== Span-Based Correction ============\n",
      "TP\tFP\tFN\tPrec\tRec\tF0.5\n",
      "973\t511\t1400\t0.6557\t0.41\t0.5855\n",
      "==============================================\n",
      "\n",
      "\n",
      "Evaluate : ../../../generate/rogec/1gb-dataset/large/large-beam-search-8.json\n",
      "\n",
      "\\Results for model: large, decoder method: large-beam-search-8 trained on the ds: 1gb-dataset\n",
      "\n",
      "=========== Span-Based Correction ============\n",
      "TP\tFP\tFN\tPrec\tRec\tF0.5\n",
      "975\t515\t1398\t0.6544\t0.4109\t0.585\n",
      "==============================================\n",
      "\n",
      "\n",
      "Evaluate : ../../../generate/rogec/1gb-dataset/large/large-greedy.json\n",
      "\n",
      "\\Results for model: large, decoder method: large-greedy trained on the ds: 1gb-dataset\n",
      "\n",
      "=========== Span-Based Correction ============\n",
      "TP\tFP\tFN\tPrec\tRec\tF0.5\n",
      "980\t531\t1393\t0.6486\t0.413\t0.5822\n",
      "==============================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluation()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}